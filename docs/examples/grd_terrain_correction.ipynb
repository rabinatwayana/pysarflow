{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e4119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geocoding: \n",
    "#     - Transform SAR coordinates to map coords\n",
    "#     - SAR image, orbit info, ellipsoid\n",
    "#     - Map-projected image\n",
    "#     - Coordinate system change\n",
    "\n",
    "# Terrain Correction: \n",
    "#     - Correct distortions due to terrain\n",
    "#     - SAR image + DEM + orbit data\n",
    "#     - Geometrically accurate map-projected image\n",
    "#     - Topographic distortion correction\n",
    "\n",
    "# forward geocoding projects SAR image data onto a map projection, \n",
    "# while backward geocoding transforms data from a map projection to the SAR sensor's geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eae6c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.7.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.holoviz.org/panel/1.7.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='e78c95d9-f65b-47ac-8537-0fd4e09339e2'>\n",
       "  <div id=\"b46812f4-f50f-45c8-afee-977bd0fc1c55\" data-root-id=\"e78c95d9-f65b-47ac-8537-0fd4e09339e2\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"a61707ec-e254-4194-934c-2718b88f589f\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"e78c95d9-f65b-47ac-8537-0fd4e09339e2\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"892f249f-6d0f-4bdf-8d47-54596e937f23\",\"attributes\":{\"plot_id\":\"e78c95d9-f65b-47ac-8537-0fd4e09339e2\",\"comm_id\":\"d9f4921075b64b808479f45418de5eb5\",\"client_comm_id\":\"70b2da2636a844b3afed72f69ddeaed8\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"a61707ec-e254-4194-934c-2718b88f589f\",\"roots\":{\"e78c95d9-f65b-47ac-8537-0fd4e09339e2\":\"b46812f4-f50f-45c8-afee-977bd0fc1c55\"},\"root_ids\":[\"e78c95d9-f65b-47ac-8537-0fd4e09339e2\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "e78c95d9-f65b-47ac-8537-0fd4e09339e2"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rabinatwayana/Rabina/CDE II/software_development/py_sar_flow\n",
      "Loading band VV from docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE/measurement/s1a-iw-grd-vv-20241209t015852-20241209t015917-056909-06fd49-001.tiff\n",
      "Loading band VH from docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE/measurement/s1a-iw-grd-vh-20241209t015852-20241209t015917-056909-06fd49-002.tiff\n",
      "Data loaded successfully\n",
      "Reading calibration for VV band\n",
      "Reading calibration for VH band\n",
      "Radiometric calibration LUT created successfully\n",
      "Radiometric calibration completed successfully\n"
     ]
    }
   ],
   "source": [
    "from pysarflow import Sentinel1GRDProcessor, parse_beta_lut\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/rabinatwayana/Rabina/CDE II/software_development/py_sar_flow/\")\n",
    "!pwd\n",
    "\n",
    "processor = Sentinel1GRDProcessor()\n",
    "# Testing read_grd_data \n",
    "# safe_path = r'C:\\Users\\Ethel Ogallo\\Documents\\CDE\\PLUS\\SS25\\practice_softwaredev\\pysarflow\\docs\\ethel_temp\\S1C_IW_GRDH_1SDV_20250527T181900_20250527T181925_002520_0053F6_70DB_COG.zip'\n",
    "# if reading zip file\n",
    "zip_safe_path = \"docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE\"\n",
    "# zip_safe_path = \"docs/data/S1B_IW_GRDH_1SDV_20211223T051122_20211223T051147_030148_039993_5371.SAFE\"\n",
    "safe_extract_path= \"docs/data/\"\n",
    "ds = processor.read_grd_data(zip_safe_path,safe_extract_path)\n",
    "\n",
    "radiometric_calibrated_ds=processor.radiometric_calibration(zip_safe_path,ds,\"sigmaNought\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db9af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://registry.opendata.aws/terrain-tiles/\n",
    "# https://www.mapzen.com/blog/terrain-tile-service/ #skadi is unprojected latlon\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def get_tile_names(lon_min, lat_min, lon_max, lat_max):\n",
    "    lons = range(int(np.floor(lon_min)), int(np.ceil(lon_max)))\n",
    "    lats = range(int(np.floor(lat_min)), int(np.ceil(lat_max)))\n",
    "    tiles = []\n",
    "    for lat in lats:\n",
    "        for lon in lons:\n",
    "            ns = \"N\" if lat >= 0 else \"S\"\n",
    "            ew = \"E\" if lon >= 0 else \"W\"\n",
    "            tile = f\"{ns}{abs(lat):02d}{ew}{abs(lon):03d}\"\n",
    "            tiles.append(tile)\n",
    "    return tiles\n",
    "\n",
    "def download_and_unzip_tile(tile_name, dest_dir):\n",
    "    url = f\"https://s3.amazonaws.com/elevation-tiles-prod/skadi/{tile_name[:3]}/{tile_name}.hgt.gz\"\n",
    "    gz_path = os.path.join(dest_dir, f\"{tile_name}.hgt.gz\")\n",
    "    hgt_path = os.path.join(dest_dir, f\"{tile_name}.hgt\")\n",
    "\n",
    "    if not os.path.exists(hgt_path):\n",
    "        print(f\"Downloading {tile_name}...\")\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Tile {tile_name} not found!\")\n",
    "            return None\n",
    "        with open(gz_path, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(hgt_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"{tile_name} downloaded and extracted.\")\n",
    "    return hgt_path\n",
    "\n",
    "def hgt_to_raster(hgt_path, tile_name):\n",
    "    lat = int(tile_name[1:3]) * (1 if tile_name[0] == 'N' else -1)\n",
    "    lon = int(tile_name[4:7]) * (1 if tile_name[3] == 'E' else -1)\n",
    "    data = np.fromfile(hgt_path, dtype='>i2')\n",
    "    size = int(np.sqrt(data.size))\n",
    "    data = data.reshape((size, size))\n",
    "    transform = rasterio.transform.from_origin(lon, lat + 1, 1 / (size - 1), 1 / (size - 1))\n",
    "    \n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'int16',\n",
    "        'nodata': -32768,\n",
    "        'width': size,\n",
    "        'height': size,\n",
    "        'count': 1,\n",
    "        'crs': 'EPSG:4326',\n",
    "        'transform': transform\n",
    "    }\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.tif')\n",
    "    with rasterio.open(temp_file.name, 'w', **profile) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "    return temp_file.name\n",
    "\n",
    "def download_dem(lon_min, lat_min, lon_max, lat_max, output_dem_path):\n",
    "    # Main workflow\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    tile_names = get_tile_names(lon_min, lat_min, lon_max, lat_max)\n",
    "\n",
    "    raster_paths = []\n",
    "    for tile in tile_names:\n",
    "        hgt_file = download_and_unzip_tile(tile, temp_dir)\n",
    "        if hgt_file:\n",
    "            raster_path = hgt_to_raster(hgt_file, tile)\n",
    "            raster_paths.append(raster_path)\n",
    "\n",
    "    # Merge tiles\n",
    "    srcs = [rasterio.open(p) for p in raster_paths]\n",
    "    mosaic, out_trans = merge(srcs)\n",
    "\n",
    "    # Clip to bbox\n",
    "    bbox = box(lon_min, lat_min, lon_max, lat_max)\n",
    "    geo = [bbox.__geo_interface__]\n",
    "    out_image, out_transform = mask(dataset=rasterio.open(raster_paths[0]), shapes=geo, crop=True)\n",
    "\n",
    "    # Update metadata\n",
    "    out_meta = srcs[0].meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"compress\": \"deflate\",\n",
    "        \"predictor\": 2,\n",
    "        \"zlevel\": 9,\n",
    "    })\n",
    "\n",
    "    # Save clipped DEM\n",
    "    # dem_clipped_path = \"dem.tif\"\n",
    "    with rasterio.open(output_dem_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "\n",
    "    print(f\"\\nDEM clipped and saved to {output_dem_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982e7c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rabinatwayana/Rabina/CDE II/software_development/py_sar_flow\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ce4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from typing import Any\n",
    "\n",
    "def open_dem_raster(dem_urlpath):\n",
    "    dem_raster = xr.open_dataarray(dem_urlpath)\n",
    "    if dem_raster.y.diff(\"y\").values[0] < 0:\n",
    "        dem_raster = dem_raster.isel(y=slice(None, None, -1))\n",
    "    dem_raster.attrs[\"long_name\"] = \"elevation\"\n",
    "    dem_raster.attrs[\"units\"] = \"m\"\n",
    "    dem_raster = dem_raster.rename(\"dem\").squeeze(drop=True)\n",
    "    return dem_raster\n",
    "\n",
    "dem_raster=open_dem_raster(\"docs/examples/dem.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9444c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code provides a pipeline to convert a 2D DEM raster into a 3D geospatial representation in ECEF (Earth-Centered, Earth-Fixed) coordinates, and here's why it is necessary:\n",
    "\n",
    "🧭 Why convert a DEM to 3D ECEF coordinates?\n",
    "True 3D Geolocation:\n",
    "\n",
    "A regular DEM provides elevation values over a 2D grid (usually in a local or projected CRS like UTM).\n",
    "But for many geodetic, global modeling, or 3D visualization tasks (e.g., in satellite systems, globe rendering, or simulations), you need positions in a global 3D Cartesian reference system like ECEF (EPSG:4978).\n",
    "\n",
    "Interoperability with 3D Systems:\n",
    "ECEF coordinates are used in satellite navigation (GPS), Earth observation, and 3D engines.\n",
    "Converting to ECEF enables seamless integration with tools that require 3D Cartesian input, like Cesium, 3D GIS, or custom simulations.\n",
    "Accurate Distance and Direction Calculations:\n",
    "In ECEF space, you can compute geocentric distances, angles, and vectors without projection distortion.\n",
    "\n",
    "This is crucial in orbital mechanics, remote sensing, and sensor fusion applications.\n",
    "\n",
    "🧠 Step-by-step breakdown of the code\n",
    "✅ make_nd_dataarray(...)\n",
    "Creates a stacked 3D array from multiple 2D DataArrays (x, y, and elevation), along a new dimension (typically \"axis\"):\n",
    "\n",
    "Output has shape: [3, height, width], where:\n",
    "\n",
    "Axis 0 = x (longitude or easting)\n",
    "\n",
    "Axis 1 = y (latitude or northing)\n",
    "\n",
    "Axis 2 = z (elevation)\n",
    "\n",
    "This converts the scalar elevation field into a 3D field representing full spatial coordinates.\n",
    "\n",
    "✅ convert_to_dem_3d(...)\n",
    "Uses broadcasting to expand x and y coordinates to match the shape of the DEM grid.\n",
    "\n",
    "Assembles [x, y, z] components into one stacked DataArray.\n",
    "\n",
    "Prepares the data for transformation into another coordinate system.\n",
    "\n",
    "✅ transform_dem_3d(...)\n",
    "Transforms [x, y, z] from the original CRS (e.g., EPSG:32633 or EPSG:4326) into ECEF (EPSG:4978) using rasterio.warp.transform.\n",
    "Handles flattening and reshaping of the data.\n",
    "Outputs a new [3, height, width] DataArray in ECEF coordinates.\n",
    "\n",
    "✅ convert_to_dem_ecef(...)\n",
    "A wrapper that combines:\n",
    "\n",
    "convert_to_dem_3d → builds [x, y, z] array in original CRS\n",
    "\n",
    "transform_dem_3d → transforms it into ECEF\n",
    "\n",
    "'''\n",
    "\n",
    "from rasterio import warp\n",
    "ECEF_CRS = \"EPSG:4978\"\n",
    "import numpy as np\n",
    "\n",
    "def make_nd_dataarray(das: list[xr.DataArray], dim: str = \"axis\") -> xr.DataArray:\n",
    "    da_nd = xr.concat(das, dim=dim, coords=\"minimal\")\n",
    "    dim_attrs = {\"long_name\": \"cartesian axis index\", \"units\": 1}\n",
    "    return da_nd.assign_coords({dim: (dim, range(len(das)), dim_attrs)})\n",
    "\n",
    "def convert_to_dem_3d(\n",
    "    dem_raster: xr.DataArray,\n",
    "    dim: str = \"axis\",\n",
    "    x: str = \"x\",\n",
    "    y: str = \"y\",\n",
    "    dtype: str = \"float64\",\n",
    ") -> xr.DataArray:\n",
    "    _, dem_raster_x = xr.broadcast(dem_raster, dem_raster.coords[x].astype(dtype))\n",
    "    dem_raster_y = dem_raster.coords[y].astype(dtype)\n",
    "    dem_raster_astype = dem_raster.astype(dtype)\n",
    "    dem_3d = make_nd_dataarray([dem_raster_x, dem_raster_y, dem_raster_astype], dim=dim)\n",
    "    dem_3d.attrs.clear()\n",
    "    dem_3d.attrs.update(dem_raster.attrs)\n",
    "    return dem_3d.rename(\"dem_3d\")\n",
    "\n",
    "\n",
    "def transform_dem_3d(\n",
    "    dem_3d: xr.DataArray,\n",
    "    source_crs: str | None = None,\n",
    "    target_crs: str = ECEF_CRS,\n",
    "    dim: str = \"axis\",\n",
    ") -> xr.DataArray:\n",
    "    if source_crs is None:\n",
    "        source_crs = dem_3d.rio.crs\n",
    "    try:\n",
    "        x, y, z = warp.transform(\n",
    "            source_crs,\n",
    "            target_crs,\n",
    "            dem_3d.sel({dim: 0}).values.flat,\n",
    "            dem_3d.sel({dim: 1}).values.flat,\n",
    "            dem_3d.sel({dim: 2}).values.flat,\n",
    "        )\n",
    "    except Exception:\n",
    "        # HACK: the very first call to warp.transform sometimes fails\n",
    "        # LOGGER.warn(\"rasterio.warp.transform failed, retrying...\")\n",
    "        x, y, z = warp.transform(\n",
    "            source_crs,\n",
    "            target_crs,\n",
    "            dem_3d.sel({dim: 0}).values.flat,\n",
    "            dem_3d.sel({dim: 1}).values.flat,\n",
    "            dem_3d.sel({dim: 2}).values.flat,\n",
    "        )\n",
    "    dem_3d_crs: xr.DataArray = xr.zeros_like(dem_3d)\n",
    "    shape = dem_3d_crs.loc[{dim: 0}].shape\n",
    "    dem_3d_crs.loc[{dim: 0}] = np.reshape(x, shape)\n",
    "    dem_3d_crs.loc[{dim: 1}] = np.reshape(y, shape)\n",
    "    dem_3d_crs.loc[{dim: 2}] = np.reshape(z, shape)\n",
    "    return dem_3d_crs\n",
    "\n",
    "def convert_to_dem_ecef(\n",
    "    dem_raster: xr.DataArray, x: str = \"x\", y: str = \"y\", **kwargs: Any\n",
    ") -> xr.DataArray:\n",
    "    dem_3d = convert_to_dem_3d(dem_raster, x=x, y=y)\n",
    "    return transform_dem_3d(dem_3d, **kwargs)\n",
    "\n",
    "dem_ecef= convert_to_dem_ecef(dem_raster)\n",
    "\n",
    "template_raster = dem_ecef.isel(axis=0).drop_vars([\"axis\", \"spatial_ref\"]) * 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab29780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def open_orbit_state_vectors(xml_path: str) -> xr.DataArray:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find all <position> elements (adjust tag path if necessary)\n",
    "    position_elements = root.findall(\".//position\")\n",
    "\n",
    "    # Lists to store extracted values\n",
    "    x_vals, y_vals, z_vals, times = [], [], [], []\n",
    "\n",
    "    for pos in position_elements:\n",
    "        x = float(pos.findtext(\"x\"))\n",
    "        y = float(pos.findtext(\"y\"))\n",
    "        z = float(pos.findtext(\"z\"))\n",
    "\n",
    "        time_tag = pos.find(\"time\")  # optional, if <time> exists\n",
    "        if time_tag is not None:\n",
    "            times.append(np.datetime64(time_tag.text))\n",
    "        else:\n",
    "            times.append(None)\n",
    "\n",
    "        x_vals.append(x)\n",
    "        y_vals.append(y)\n",
    "        z_vals.append(z)\n",
    "\n",
    "    # Create axis-wise array: (time, axis)\n",
    "    data = np.vstack([x_vals, y_vals, z_vals]).T\n",
    "\n",
    "    # Build DataArray\n",
    "    coords = {\n",
    "        \"axis\": [\"x\", \"y\", \"z\"],\n",
    "        \"azimuth_time\": times if times[0] is not None else np.arange(len(x_vals)),\n",
    "    }\n",
    "\n",
    "    position_da = xr.DataArray(\n",
    "        data,\n",
    "        dims=(\"azimuth_time\", \"axis\"),\n",
    "        coords=coords,\n",
    "        name=\"position\"\n",
    "    )\n",
    "\n",
    "    return position_da\n",
    "\n",
    "\n",
    "position= open_orbit_state_vectors(\"docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE/annotation/s1a-iw-grd-vh-20241209t015852-20241209t015917-056909-06fd49-002_updated.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b42413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;position&#x27; (azimuth_time: 9361, axis: 3)&gt; Size: 225kB\n",
       "array([[  265648.7,  2597883. , -6582910. ],\n",
       "       [  289721.7,  2530676. , -6608037. ],\n",
       "       [  313664.3,  2463152. , -6632425. ],\n",
       "       ...,\n",
       "       [ 1703554. ,  6853118. ,   456615.3],\n",
       "       [ 1720016. ,  6853642. ,   382447.3],\n",
       "       [ 1736285. ,  6853374. ,   308236.1]], shape=(9361, 3))\n",
       "Coordinates:\n",
       "  * axis          (axis) &lt;U1 12B &#x27;x&#x27; &#x27;y&#x27; &#x27;z&#x27;\n",
       "  * azimuth_time  (azimuth_time) int64 75kB 0 1 2 3 4 ... 9357 9358 9359 9360</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'position'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>azimuth_time</span>: 9361</li><li><span class='xr-has-index'>axis</span>: 3</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-85144953-538d-4448-b996-9a74c42c6642' class='xr-array-in' type='checkbox' checked><label for='section-85144953-538d-4448-b996-9a74c42c6642' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>2.656e+05 2.598e+06 -6.583e+06 ... 1.736e+06 6.853e+06 3.082e+05</span></div><div class='xr-array-data'><pre>array([[  265648.7,  2597883. , -6582910. ],\n",
       "       [  289721.7,  2530676. , -6608037. ],\n",
       "       [  313664.3,  2463152. , -6632425. ],\n",
       "       ...,\n",
       "       [ 1703554. ,  6853118. ,   456615.3],\n",
       "       [ 1720016. ,  6853642. ,   382447.3],\n",
       "       [ 1736285. ,  6853374. ,   308236.1]], shape=(9361, 3))</pre></div></div></li><li class='xr-section-item'><input id='section-c931f51f-6fa5-4ff2-a78a-f720ea1e7701' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c931f51f-6fa5-4ff2-a78a-f720ea1e7701' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>axis</span></div><div class='xr-var-dims'>(axis)</div><div class='xr-var-dtype'>&lt;U1</div><div class='xr-var-preview xr-preview'>&#x27;x&#x27; &#x27;y&#x27; &#x27;z&#x27;</div><input id='attrs-51b8e0b9-a04a-4ac0-a5a8-1c5187823899' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-51b8e0b9-a04a-4ac0-a5a8-1c5187823899' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4792fed2-0458-467a-99e5-654b2653fb53' class='xr-var-data-in' type='checkbox'><label for='data-4792fed2-0458-467a-99e5-654b2653fb53' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;], dtype=&#x27;&lt;U1&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>azimuth_time</span></div><div class='xr-var-dims'>(azimuth_time)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 ... 9357 9358 9359 9360</div><input id='attrs-99337c41-de88-40ef-af0e-f171cf78a07e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-99337c41-de88-40ef-af0e-f171cf78a07e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4c73b328-9352-4615-a445-4e6914def171' class='xr-var-data-in' type='checkbox'><label for='data-4c73b328-9352-4615-a445-4e6914def171' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([   0,    1,    2, ..., 9358, 9359, 9360], shape=(9361,))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2f7073de-b308-4a58-bcec-6768f40bf9ce' class='xr-section-summary-in' type='checkbox'  ><label for='section-2f7073de-b308-4a58-bcec-6768f40bf9ce' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>axis</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-79612893-68d3-4d8a-83dc-399acefd968c' class='xr-index-data-in' type='checkbox'/><label for='index-79612893-68d3-4d8a-83dc-399acefd968c' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;], dtype=&#x27;object&#x27;, name=&#x27;axis&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>azimuth_time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-1d6ae08b-c062-4f26-a744-c76a9f8ec655' class='xr-index-data-in' type='checkbox'/><label for='index-1d6ae08b-c062-4f26-a744-c76a9f8ec655' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       9351, 9352, 9353, 9354, 9355, 9356, 9357, 9358, 9359, 9360],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;azimuth_time&#x27;, length=9361))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-10d9fe16-1d5f-4f98-b0c8-e029b724bdd4' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-10d9fe16-1d5f-4f98-b0c8-e029b724bdd4' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'position' (azimuth_time: 9361, axis: 3)> Size: 225kB\n",
       "array([[  265648.7,  2597883. , -6582910. ],\n",
       "       [  289721.7,  2530676. , -6608037. ],\n",
       "       [  313664.3,  2463152. , -6632425. ],\n",
       "       ...,\n",
       "       [ 1703554. ,  6853118. ,   456615.3],\n",
       "       [ 1720016. ,  6853642. ,   382447.3],\n",
       "       [ 1736285. ,  6853374. ,   308236.1]], shape=(9361, 3))\n",
       "Coordinates:\n",
       "  * axis          (axis) <U1 12B 'x' 'y' 'z'\n",
       "  * azimuth_time  (azimuth_time) int64 75kB 0 1 2 3 4 ... 9357 9358 9359 9360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3638ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'polyfit_coefficients' (degree: 6, axis: 3)> Size: 144B\n",
      "array([[-6.79253857e+32,  2.80983471e+33,  4.30702494e+33],\n",
      "       [ 1.26630472e+27, -3.70734756e+27,  2.65483220e+27],\n",
      "       [ 1.27249839e+22, -5.70023956e+22, -8.72813139e+22],\n",
      "       [-1.86941015e+16,  4.93048076e+16, -3.54855470e+16],\n",
      "       [-4.34705250e+10,  2.11963260e+11,  3.23248314e+11],\n",
      "       [ 2.88420694e+04, -6.91790330e+04,  3.78346625e+04]])\n",
      "Coordinates:\n",
      "  * degree   (degree) int64 48B 5 4 3 2 1 0\n",
      "  * axis     (axis) <U1 12B 'x' 'y' 'z'\n",
      "Epoch: 1970-01-01T00:00:00.000004680\n",
      "Valid interval: (np.int64(0), np.int64(9360))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "def polyder(coefficients: xr.DataArray) -> xr.DataArray:\n",
    "    # TODO: raise if \"degree\" coord is not decreasing\n",
    "    derivative_coefficients = coefficients.isel(degree=slice(1, None)).copy()\n",
    "    for degree in coefficients.coords[\"degree\"].values[:-1]:\n",
    "        derivative_coefficients.loc[{\"degree\": degree - 1}] = (\n",
    "            coefficients.loc[{\"degree\": degree}] * degree\n",
    "        )\n",
    "    return derivative_coefficients\n",
    "\n",
    "def orb_poly_fit_from_position(\n",
    "    position: xr.DataArray,\n",
    "    dim: str = \"azimuth_time\",\n",
    "    deg: int = 5,\n",
    "    epoch: np.datetime64 = None,\n",
    "    interval: tuple[np.datetime64, np.datetime64] = None,\n",
    "):\n",
    "    time = position.coords[dim]\n",
    "\n",
    "    # Set epoch to the midpoint of time range if not provided\n",
    "    if epoch is None:\n",
    "        start = time.values[0].astype(\"datetime64[ns]\")\n",
    "        end = time.values[-1].astype(\"datetime64[ns]\")\n",
    "        epoch = start + (end - start) // 2\n",
    "        # epoch = time.values[0] + (time.values[-1] - time.values[0]) / 2\n",
    "\n",
    "    # Set interpolation interval if not provided\n",
    "    if interval is None:\n",
    "        interval = (time.values[0], time.values[-1])\n",
    "\n",
    "    # Convert time to seconds since epoch (safely)\n",
    "    orbit_time_vals = (\n",
    "        (time.values.astype(\"datetime64[ns]\") - epoch.astype(\"datetime64[ns]\"))\n",
    "        / np.timedelta64(1, \"s\")\n",
    "    ).astype(\"float64\")\n",
    "\n",
    "    # Assign the new numeric time coordinate\n",
    "    orbit_time = xr.DataArray(orbit_time_vals, coords={dim: time}, dims=dim)\n",
    "    data = position.assign_coords({dim: orbit_time})\n",
    "\n",
    "    # Fit polynomial for each axis (x/y/z)\n",
    "    polyfit_results = data.polyfit(dim=dim, deg=deg)\n",
    "\n",
    "    return {\n",
    "        \"coefficients\": polyfit_results.polyfit_coefficients,\n",
    "        \"epoch\": epoch,\n",
    "        \"interval\": interval,\n",
    "    }\n",
    "\n",
    "# Assume `position` is a DataArray with coords like azimuth_time and axis (x/y/z)\n",
    "orbit_interpolator = orb_poly_fit_from_position(position)\n",
    "\n",
    "coefficients=orbit_interpolator[\"coefficients\"]\n",
    "velocity_coefficients=polyder(coefficients)\n",
    "epoch= orbit_interpolator[\"epoch\"]\n",
    "\n",
    "\n",
    "print(orbit_interpolator[\"coefficients\"])\n",
    "print(\"Epoch:\", orbit_interpolator[\"epoch\"])\n",
    "print(\"Valid interval:\", orbit_interpolator[\"interval\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c3608",
   "metadata": {},
   "source": [
    "# Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c032d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reference \"Guide to Sentinel-1 Geocoding\" UZH-S1-GC-AD 1.10 26.03.2019.\n",
    "\n",
    "See: https://sentinel.esa.int/documents/247904/0/Guide-to-Sentinel-1-Geocoding.pdf/e0450150-b4e9-4b2d-9b32-dadf989d3bd3\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "from typing import Any, Callable, TypeVar\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import xarray as xr\n",
    "\n",
    "# from . import orbit\n",
    "\n",
    "ArrayLike = TypeVar(\"ArrayLike\", bound=npt.ArrayLike)\n",
    "FloatArrayLike = TypeVar(\"FloatArrayLike\", bound=npt.ArrayLike)\n",
    "\n",
    "\n",
    "def secant_method(\n",
    "    ufunc: Callable[[ArrayLike], tuple[FloatArrayLike, Any]],\n",
    "    t_prev: ArrayLike,\n",
    "    t_curr: ArrayLike,\n",
    "    diff_ufunc: float = 1.0,\n",
    "    diff_t: Any = 1e-6,\n",
    "    maxiter: int = 10,\n",
    ") -> tuple[ArrayLike, ArrayLike, FloatArrayLike, int, Any]:\n",
    "    \"\"\"Return the root of ufunc calculated using the secant method.\"\"\"\n",
    "    # implementation modified from https://en.wikipedia.org/wiki/Secant_method\n",
    "    f_prev, _ = ufunc(t_prev)\n",
    "\n",
    "    # strong convergence, all points below one of the two thresholds\n",
    "    for k in range(maxiter):\n",
    "        f_curr, payload_curr = ufunc(t_curr)\n",
    "\n",
    "        # print(f\"{f_curr / 7500}\")\n",
    "\n",
    "        # the `not np.any` construct let us accept `np.nan` as good values\n",
    "        if not np.any((np.abs(f_curr) > diff_ufunc)):\n",
    "            break\n",
    "\n",
    "        t_diff = t_curr - t_prev  # type: ignore\n",
    "\n",
    "        # the `not np.any` construct let us accept `np.nat` as good values\n",
    "        if not np.any(np.abs(t_diff) > diff_t):\n",
    "            break\n",
    "\n",
    "        q = f_curr - f_prev  # type: ignore\n",
    "\n",
    "        # NOTE: in same cases f_curr * t_diff overflows datetime64[ns] before the division by q\n",
    "        t_prev, t_curr = t_curr, t_curr - np.where(q != 0, f_curr / q, 0) * t_diff  # type: ignore\n",
    "        f_prev = f_curr\n",
    "\n",
    "    return t_curr, t_prev, f_curr, k, payload_curr\n",
    "\n",
    "\n",
    "def newton_raphson_method(\n",
    "    ufunc: Callable[[ArrayLike], tuple[FloatArrayLike, Any]],\n",
    "    ufunc_prime: Callable[[ArrayLike, Any], FloatArrayLike],\n",
    "    t_curr: ArrayLike,\n",
    "    diff_ufunc: float = 1.0,\n",
    "    diff_t: Any = 1e-6,\n",
    "    maxiter: int = 10,\n",
    ") -> tuple[ArrayLike, FloatArrayLike, int, Any]:\n",
    "    \"\"\"Return the root of ufunc calculated using the Newton method.\"\"\"\n",
    "    # implementation based on https://en.wikipedia.org/wiki/Newton%27s_method\n",
    "    # strong convergence, all points below one of the two thresholds\n",
    "    for k in range(maxiter):\n",
    "        f_curr, payload_curr = ufunc(t_curr)\n",
    "\n",
    "        # print(f\"{f_curr / 7500}\")\n",
    "\n",
    "        # the `not np.any` construct let us accept `np.nan` as good values\n",
    "        if not np.any((np.abs(f_curr) > diff_ufunc)):\n",
    "            break\n",
    "\n",
    "        fp_curr = ufunc_prime(t_curr, payload_curr)\n",
    "\n",
    "        t_diff = f_curr / fp_curr  # type: ignore\n",
    "\n",
    "        # the `not np.any` construct let us accept `np.nat` as good values\n",
    "        if not np.any(np.abs(t_diff) > diff_t):\n",
    "            break\n",
    "\n",
    "        t_curr = t_curr - t_diff  # type: ignore\n",
    "\n",
    "    return t_curr, f_curr, k, payload_curr\n",
    "\n",
    "def position_from_orbit_time(orbit_time: xr.DataArray) -> xr.DataArray:\n",
    "        position = xr.polyval(orbit_time, coefficients)\n",
    "        return position.rename(\"position\")\n",
    "\n",
    "def velocity_from_orbit_time(orbit_time: xr.DataArray) -> xr.DataArray:\n",
    "        velocity = xr.polyval(orbit_time, velocity_coefficients)\n",
    "        return velocity.rename(\"velocity\")\n",
    "\n",
    "def zero_doppler_plane_distance_velocity(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    orbit_interpolator,\n",
    "    orbit_time: xr.DataArray,\n",
    "    dim: str = \"axis\",\n",
    ") -> tuple[xr.DataArray, tuple[xr.DataArray, xr.DataArray]]:\n",
    "    dem_distance = dem_ecef - position_from_orbit_time(orbit_time)\n",
    "    satellite_velocity = velocity_from_orbit_time(orbit_time)\n",
    "    plane_distance_velocity = (dem_distance * satellite_velocity).sum(dim, skipna=False)\n",
    "    return plane_distance_velocity, (dem_distance, satellite_velocity)\n",
    "\n",
    "\n",
    "def zero_doppler_plane_distance_velocity_prime(\n",
    "    orbit_interpolator,\n",
    "    orbit_time: xr.DataArray,\n",
    "    payload: tuple[xr.DataArray, xr.DataArray],\n",
    "    dim: str = \"axis\",\n",
    ") -> xr.DataArray:\n",
    "    dem_distance, satellite_velocity = payload\n",
    "\n",
    "    plane_distance_velocity_prime = (\n",
    "        dem_distance * orbit_interpolator.acceleration_from_orbit_time(orbit_time)\n",
    "        - satellite_velocity**2\n",
    "    ).sum(dim)\n",
    "    return plane_distance_velocity_prime\n",
    "\n",
    "\n",
    "def backward_geocode_simple(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    orbit_interpolator,\n",
    "    orbit_time_guess: xr.DataArray | float = 0.0,\n",
    "    dim: str = \"axis\",\n",
    "    zero_doppler_distance: float = 1.0,\n",
    "    satellite_speed: float = 7_500.0,\n",
    "    method: str = \"secant\",\n",
    "    orbit_time_prev_shift: float = -0.1,\n",
    "    maxiter: int = 10,\n",
    ") -> tuple[xr.DataArray, xr.DataArray, xr.DataArray]:\n",
    "    diff_ufunc = zero_doppler_distance * satellite_speed\n",
    "\n",
    "    zero_doppler = functools.partial(\n",
    "        zero_doppler_plane_distance_velocity, dem_ecef, orbit_interpolator\n",
    "    )\n",
    "\n",
    "    if isinstance(orbit_time_guess, xr.DataArray):\n",
    "        pass\n",
    "    else:\n",
    "        t_template = dem_ecef.isel({dim: 0}).drop_vars(dim).rename(\"azimuth_time\")\n",
    "        orbit_time_guess = xr.full_like(\n",
    "            t_template,\n",
    "            orbit_time_guess,\n",
    "            dtype=\"float64\",\n",
    "        )\n",
    "\n",
    "    if method == \"secant\":\n",
    "        orbit_time_guess_prev = orbit_time_guess + orbit_time_prev_shift\n",
    "        orbit_time, _, _, k, (dem_distance, satellite_velocity) = secant_method(\n",
    "            zero_doppler,\n",
    "            orbit_time_guess_prev,\n",
    "            orbit_time_guess,\n",
    "            diff_ufunc,\n",
    "            maxiter=maxiter,\n",
    "        )\n",
    "    elif method in {\"newton\", \"newton_raphson\"}:\n",
    "        zero_doppler_prime = functools.partial(\n",
    "            zero_doppler_plane_distance_velocity_prime, orbit_interpolator\n",
    "        )\n",
    "        orbit_time, _, k, (dem_distance, satellite_velocity) = newton_raphson_method(\n",
    "            zero_doppler,\n",
    "            zero_doppler_prime,\n",
    "            orbit_time_guess,\n",
    "            diff_ufunc,\n",
    "            maxiter=maxiter,\n",
    "        )\n",
    "    # print(f\"iterations: {k}\")\n",
    "    return orbit_time, dem_distance, satellite_velocity\n",
    "\n",
    "S_TO_NS = 10**9\n",
    "# def orbit_time_to_azimuth_time(\n",
    "#     orbit_time: xr.DataArray, epoch: np.datetime64\n",
    "# ) -> xr.DataArray:\n",
    "#     azimuth_time = orbit_time * np.timedelta64(S_TO_NS, \"ns\") + epoch\n",
    "#     return azimuth_time.rename(\"azimuth_time\")\n",
    "\n",
    "def orbit_time_to_azimuth_time(orbit_time: xr.DataArray, epoch: np.datetime64) -> xr.DataArray:\n",
    "    # Convert float seconds to int64 nanoseconds for timedelta64[ns]\n",
    "    time_deltas = xr.apply_ufunc(\n",
    "        lambda x: x.astype(\"timedelta64[ns]\"),\n",
    "        (orbit_time * 1e9).astype(\"int64\")\n",
    "    )\n",
    "    print(type(time_deltas), type(epoch),\"**************************\")\n",
    "\n",
    "    azimuth_time = epoch + time_deltas\n",
    "    return azimuth_time.rename(\"azimuth_time\")\n",
    "\n",
    "\n",
    "\n",
    "def backward_geocode(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    orbit_interpolator,\n",
    "    orbit_time_guess: xr.DataArray | float = 0.0,\n",
    "    dim: str = \"axis\",\n",
    "    zero_doppler_distance: float = 1.0,\n",
    "    satellite_speed: float = 7_500.0,\n",
    "    method: str = \"newton\",\n",
    "    seed_step: tuple[int, int] | None = None,\n",
    "    maxiter: int = 10,\n",
    "    maxiter_after_seed: int = 1,\n",
    "    orbit_time_prev_shift: float = -0.1,\n",
    ") -> xr.Dataset:\n",
    "    if seed_step is not None:\n",
    "        dem_ecef_seed = dem_ecef.isel(\n",
    "            y=slice(seed_step[0] // 2, None, seed_step[0]),\n",
    "            x=slice(seed_step[1] // 2, None, seed_step[1]),\n",
    "        )\n",
    "        orbit_time_seed, _, _ = backward_geocode_simple(\n",
    "            dem_ecef_seed,\n",
    "            orbit_interpolator,\n",
    "            orbit_time_guess,\n",
    "            dim,\n",
    "            zero_doppler_distance,\n",
    "            satellite_speed,\n",
    "            method,\n",
    "            orbit_time_prev_shift=orbit_time_prev_shift,\n",
    "        )\n",
    "        orbit_time_guess = orbit_time_seed.interp_like(\n",
    "            dem_ecef.sel(axis=0), kwargs={\"fill_value\": \"extrapolate\"}\n",
    "        )\n",
    "        maxiter = maxiter_after_seed\n",
    "\n",
    "    orbit_time, dem_distance, satellite_velocity = backward_geocode_simple(\n",
    "        dem_ecef,\n",
    "        orbit_interpolator,\n",
    "        orbit_time_guess,\n",
    "        dim,\n",
    "        zero_doppler_distance,\n",
    "        satellite_speed,\n",
    "        method,\n",
    "        maxiter=maxiter,\n",
    "        orbit_time_prev_shift=orbit_time_prev_shift,\n",
    "    )\n",
    "\n",
    "    acquisition = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"azimuth_time\": orbit_time_to_azimuth_time(orbit_time, epoch),\n",
    "            \"dem_distance\": dem_distance,\n",
    "            \"satellite_velocity\": satellite_velocity.transpose(*dem_distance.dims),\n",
    "        }\n",
    "    )\n",
    "    return acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286e7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from unittest import mock\n",
    "\n",
    "import flox.xarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# from . import scene\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ONE_SECOND = np.timedelta64(10**9, \"ns\")\n",
    "\n",
    "\n",
    "def sum_weights(\n",
    "    initial_weights: xr.DataArray,\n",
    "    azimuth_index: xr.DataArray,\n",
    "    slant_range_index: xr.DataArray,\n",
    "    multilook: tuple[int, int] | None = None,\n",
    ") -> xr.DataArray:\n",
    "    geocoded = initial_weights.assign_coords(\n",
    "        slant_range_index=slant_range_index, azimuth_index=azimuth_index\n",
    "    )\n",
    "\n",
    "    flat_sum: xr.DataArray = flox.xarray.xarray_reduce(\n",
    "        geocoded,\n",
    "        geocoded.slant_range_index,\n",
    "        geocoded.azimuth_index,\n",
    "        func=\"sum\",\n",
    "        method=\"map-reduce\",\n",
    "    )\n",
    "\n",
    "    if multilook:\n",
    "        flat_sum = flat_sum.rolling(\n",
    "            azimuth_index=multilook[0],\n",
    "            slant_range_index=multilook[1],\n",
    "            center=True,\n",
    "            min_periods=multilook[0] * multilook[1] // 2 + 1,\n",
    "        ).mean()\n",
    "\n",
    "    with mock.patch(\"xarray.core.missing._localize\", lambda o, i: (o, i)):\n",
    "        weights_sum = flat_sum.interp(\n",
    "            slant_range_index=slant_range_index,\n",
    "            azimuth_index=azimuth_index,\n",
    "            method=\"nearest\",\n",
    "        )\n",
    "\n",
    "    return weights_sum\n",
    "\n",
    "\n",
    "def compute_dem_oriented_area(dem_ecef: xr.DataArray) -> xr.DataArray:\n",
    "    x_corners: npt.ArrayLike = np.concatenate(\n",
    "        [\n",
    "            [dem_ecef.x[0] + (dem_ecef.x[0] - dem_ecef.x[1]) / 2],\n",
    "            ((dem_ecef.x.shift(x=-1) + dem_ecef.x) / 2)[:-1].data,\n",
    "            [dem_ecef.x[-1] + (dem_ecef.x[-1] - dem_ecef.x[-2]) / 2],\n",
    "        ]\n",
    "    )\n",
    "    y_corners: npt.ArrayLike = np.concatenate(\n",
    "        [\n",
    "            [dem_ecef.y[0] + (dem_ecef.y[0] - dem_ecef.y[1]) / 2],\n",
    "            ((dem_ecef.y.shift(y=-1) + dem_ecef.y) / 2)[:-1].data,\n",
    "            [dem_ecef.y[-1] + (dem_ecef.y[-1] - dem_ecef.y[-2]) / 2],\n",
    "        ]\n",
    "    )\n",
    "    dem_ecef_corners = dem_ecef.interp(\n",
    "        {\"x\": x_corners, \"y\": y_corners},\n",
    "        method=\"linear\",\n",
    "        kwargs={\"fill_value\": \"extrapolate\"},\n",
    "    )\n",
    "\n",
    "    dx = dem_ecef_corners.diff(\"x\", 1)\n",
    "    dy = dem_ecef_corners.diff(\"y\", 1)\n",
    "\n",
    "    dx1 = dx.isel(y=slice(1, None)).assign_coords(dem_ecef.coords)\n",
    "    dy1 = dy.isel(x=slice(1, None)).assign_coords(dem_ecef.coords)\n",
    "    dx2 = dx.isel(y=slice(None, -1)).assign_coords(dem_ecef.coords)\n",
    "    dy2 = dy.isel(x=slice(None, -1)).assign_coords(dem_ecef.coords)\n",
    "\n",
    "    cross_1 = xr.cross(dx1, dy1, dim=\"axis\") / 2\n",
    "    sign_1 = np.sign(\n",
    "        xr.dot(cross_1, dem_ecef, dim=\"axis\")\n",
    "    )  # ensure direction out of DEM\n",
    "\n",
    "    cross_2 = xr.cross(dx2, dy2, dim=\"axis\") / 2\n",
    "    sign_2 = np.sign(\n",
    "        xr.dot(cross_2, dem_ecef, dim=\"axis\")\n",
    "    )  # ensure direction out of DEM\n",
    "    dem_oriented_area: xr.DataArray = cross_1 * sign_1 + cross_2 * sign_2\n",
    "\n",
    "    return dem_oriented_area.rename(\"dem_oriented_area\")\n",
    "\n",
    "\n",
    "def compute_gamma_area(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    dem_direction: xr.DataArray,\n",
    ") -> xr.DataArray:\n",
    "    dem_oriented_area = compute_dem_oriented_area(dem_ecef)\n",
    "    gamma_area: xr.DataArray = xr.dot(dem_oriented_area, -dem_direction, dim=\"axis\")\n",
    "    gamma_area = gamma_area.where(gamma_area > 0, 0)\n",
    "    return gamma_area\n",
    "\n",
    "\n",
    "def gamma_weights_bilinear(\n",
    "    dem_coords: xr.Dataset,\n",
    "    slant_range_time0: float,\n",
    "    azimuth_time0: np.datetime64,\n",
    "    slant_range_time_interval_s: float,\n",
    "    azimuth_time_interval_s: float,\n",
    "    slant_range_spacing_m: float = 1.0,\n",
    "    azimuth_spacing_m: float = 1.0,\n",
    ") -> xr.DataArray:\n",
    "    # compute dem image coordinates\n",
    "    azimuth_index = ((dem_coords.azimuth_time - azimuth_time0) / ONE_SECOND) / (\n",
    "        azimuth_time_interval_s\n",
    "    )\n",
    "\n",
    "    slant_range_index = (dem_coords.slant_range_time - slant_range_time0) / (\n",
    "        slant_range_time_interval_s\n",
    "    )\n",
    "\n",
    "    slant_range_index_0 = np.floor(slant_range_index).astype(int).compute()\n",
    "    slant_range_index_1 = np.ceil(slant_range_index).astype(int).compute()\n",
    "    azimuth_index_0 = np.floor(azimuth_index).astype(int).compute()\n",
    "    azimuth_index_1 = np.ceil(azimuth_index).astype(int).compute()\n",
    "\n",
    "    logger.info(\"compute gamma areas 1/4\")\n",
    "    w_00 = abs(\n",
    "        (azimuth_index_1 - azimuth_index) * (slant_range_index_1 - slant_range_index)\n",
    "    )\n",
    "    tot_area_00 = sum_weights(\n",
    "        dem_coords[\"gamma_area\"] * w_00,\n",
    "        azimuth_index=azimuth_index_0,\n",
    "        slant_range_index=slant_range_index_0,\n",
    "    )\n",
    "\n",
    "    logger.info(\"compute gamma areas 2/4\")\n",
    "    w_01 = abs(\n",
    "        (azimuth_index_1 - azimuth_index) * (slant_range_index_0 - slant_range_index)\n",
    "    )\n",
    "    tot_area_01 = sum_weights(\n",
    "        dem_coords[\"gamma_area\"] * w_01,\n",
    "        azimuth_index=azimuth_index_0,\n",
    "        slant_range_index=slant_range_index_1,\n",
    "    )\n",
    "\n",
    "    logger.info(\"compute gamma areas 3/4\")\n",
    "    w_10 = abs(\n",
    "        (azimuth_index_0 - azimuth_index) * (slant_range_index_1 - slant_range_index)\n",
    "    )\n",
    "    tot_area_10 = sum_weights(\n",
    "        dem_coords[\"gamma_area\"] * w_10,\n",
    "        azimuth_index=azimuth_index_1,\n",
    "        slant_range_index=slant_range_index_0,\n",
    "    )\n",
    "\n",
    "    logger.info(\"compute gamma areas 4/4\")\n",
    "    w_11 = abs(\n",
    "        (azimuth_index_0 - azimuth_index) * (slant_range_index_0 - slant_range_index)\n",
    "    )\n",
    "    tot_area_11 = sum_weights(\n",
    "        dem_coords[\"gamma_area\"] * w_11,\n",
    "        azimuth_index=azimuth_index_1,\n",
    "        slant_range_index=slant_range_index_1,\n",
    "    )\n",
    "\n",
    "    tot_area = tot_area_00 + tot_area_01 + tot_area_10 + tot_area_11\n",
    "\n",
    "    normalized_area = tot_area / (azimuth_spacing_m * slant_range_spacing_m)\n",
    "    return normalized_area\n",
    "\n",
    "\n",
    "def gamma_weights_nearest(\n",
    "    dem_coords: xr.Dataset,\n",
    "    slant_range_time0: float,\n",
    "    azimuth_time0: np.datetime64,\n",
    "    slant_range_time_interval_s: float,\n",
    "    azimuth_time_interval_s: float,\n",
    "    slant_range_spacing_m: float = 1.0,\n",
    "    azimuth_spacing_m: float = 1.0,\n",
    ") -> xr.DataArray:\n",
    "    # compute dem image coordinates\n",
    "    azimuth_index = np.round(\n",
    "        (dem_coords.azimuth_time - azimuth_time0) / ONE_SECOND / azimuth_time_interval_s\n",
    "    ).astype(int)\n",
    "\n",
    "    slant_range_index = np.round(\n",
    "        (dem_coords.slant_range_time - slant_range_time0) / slant_range_time_interval_s\n",
    "    ).astype(int)\n",
    "\n",
    "    logger.info(\"compute gamma areas 1/1\")\n",
    "\n",
    "    tot_area = sum_weights(\n",
    "        dem_coords[\"gamma_area\"],\n",
    "        azimuth_index=azimuth_index,\n",
    "        slant_range_index=slant_range_index,\n",
    "    )\n",
    "\n",
    "    normalized_area = tot_area / (azimuth_spacing_m * slant_range_spacing_m)\n",
    "    return normalized_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426e30cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xarray.core.dataarray.DataArray'> <class 'numpy.datetime64'> **************************\n",
      "<class 'xarray.core.dataarray.DataArray'> <class 'numpy.datetime64'> **************************\n",
      "<class 'xarray.core.dataarray.DataArray'> <class 'numpy.datetime64'> **************************\n"
     ]
    }
   ],
   "source": [
    "def make_simulate_acquisition_template(\n",
    "    template_raster: xr.DataArray,\n",
    "    correct_radiometry: str | None = None,\n",
    ") -> xr.Dataset:\n",
    "    acquisition_template = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"slant_range_time\": template_raster,\n",
    "            \"azimuth_time\": template_raster.astype(\"datetime64[ns]\"),\n",
    "        }\n",
    "    )\n",
    "    include_variables = {\"slant_range_time\", \"azimuth_time\"}\n",
    "    if correct_radiometry is not None:\n",
    "        acquisition_template[\"gamma_area\"] = template_raster\n",
    "        include_variables.add(\"gamma_area\")\n",
    "\n",
    "    return acquisition_template\n",
    "\n",
    "\n",
    "\n",
    "SPEED_OF_LIGHT = 299_792_458.0  # m / s\n",
    "def simulate_acquisition(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    orbit_interpolator,\n",
    "    include_variables, #: Container[str] = ()\n",
    "    azimuth_time: xr.DataArray | float = 0.0,\n",
    "    **kwargs: Any,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Compute the image coordinates of the DEM given the satellite orbit.\"\"\"\n",
    "    acquisition = backward_geocode(\n",
    "        dem_ecef, orbit_interpolator, azimuth_time, **kwargs\n",
    "    )\n",
    "\n",
    "    slant_range = (acquisition.dem_distance**2).sum(dim=\"axis\") ** 0.5\n",
    "    slant_range_time = 2.0 / SPEED_OF_LIGHT * slant_range\n",
    "\n",
    "    acquisition[\"slant_range_time\"] = slant_range_time\n",
    "\n",
    "    if include_variables and \"gamma_area\" in include_variables:\n",
    "        gamma_area = compute_gamma_area(\n",
    "            dem_ecef, acquisition.dem_distance / slant_range\n",
    "        )\n",
    "        acquisition[\"gamma_area\"] = gamma_area\n",
    "\n",
    "    for data_var_name in acquisition.data_vars:\n",
    "        if include_variables and data_var_name not in include_variables:\n",
    "            acquisition = acquisition.drop_vars(data_var_name)  # type: ignore\n",
    "\n",
    "    # drop coordinates that are not associated with any data variable\n",
    "    for coord_name in acquisition.coords:\n",
    "        if all(coord_name not in dv.coords for dv in acquisition.data_vars.values()):\n",
    "            acquisition = acquisition.drop_vars(coord_name)  # type: ignore\n",
    "\n",
    "    return acquisition\n",
    "\n",
    "# def map_simulate_acquisition(\n",
    "#     dem_ecef: xr.DataArray,\n",
    "#     orbit_interpolator,\n",
    "#     template_raster: xr.DataArray | None = None,\n",
    "#     correct_radiometry: str | None = None,\n",
    "#     **kwargs: Any,\n",
    "# ) -> xr.Dataset:\n",
    "#     if template_raster is None:\n",
    "#         template_raster = dem_ecef.isel(axis=0).drop_vars([\"axis\", \"spatial_ref\"]) * 0.0\n",
    "#     acquisition_template = make_simulate_acquisition_template(\n",
    "#         template_raster, correct_radiometry\n",
    "#     )\n",
    "#     acquisition = xr.map_blocks(\n",
    "#         simulate_acquisition,\n",
    "#         dem_ecef.drop_vars(\"spatial_ref\"),\n",
    "#         kwargs={\n",
    "#             \"orbit_interpolator\": orbit_interpolator,\n",
    "#             \"include_variables\": list(acquisition_template.data_vars),\n",
    "#         }\n",
    "#         | kwargs,\n",
    "#         template=acquisition_template,\n",
    "#     )\n",
    "#     return acquisition\n",
    "\n",
    "def map_simulate_acquisition(\n",
    "    dem_ecef: xr.DataArray,\n",
    "    orbit_interpolator,\n",
    "    template_raster: xr.DataArray | None = None,\n",
    "    correct_radiometry: str | None = None,\n",
    "    **kwargs: Any,\n",
    ") -> xr.Dataset:\n",
    "    if template_raster is None:\n",
    "        template_raster = dem_ecef.isel(axis=0).drop_vars([\"axis\", \"spatial_ref\"]) * 0.0\n",
    "\n",
    "    acquisition_template = make_simulate_acquisition_template(\n",
    "        template_raster, correct_radiometry\n",
    "    )\n",
    "    include_variables = list(acquisition_template.data_vars)\n",
    "\n",
    "    # Get all index values for the 'axis' dimension\n",
    "    axis_dim = \"axis\" if \"axis\" in dem_ecef.dims else dem_ecef.dims[0]\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(dem_ecef.sizes[axis_dim]):\n",
    "        # Select a single chunk along the axis\n",
    "        dem_chunk = dem_ecef.isel({axis_dim: i})\n",
    "\n",
    "        # Add the axis dimension back to preserve structure\n",
    "        dem_chunk = dem_chunk.expand_dims({axis_dim: [dem_ecef[axis_dim].values[i]]})\n",
    "\n",
    "        acquisition = simulate_acquisition(\n",
    "            dem_chunk,\n",
    "            orbit_interpolator=orbit_interpolator,\n",
    "            include_variables=include_variables,\n",
    "            **kwargs\n",
    "        )\n",
    "        chunks.append(acquisition)\n",
    "\n",
    "    # Concatenate all chunk results along the 'axis' dimension\n",
    "    acquisition_all = xr.concat(chunks, dim=axis_dim)\n",
    "\n",
    "    return acquisition_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acquisition = map_simulate_acquisition(\n",
    "        dem_ecef,\n",
    "        orbit_interpolator,\n",
    "        correct_radiometry=None,\n",
    "        seed_step=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072a95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rabinatwayana/Rabina/CDE II/software_development/py_sar_flow\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91222c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_tag_as_list(\n",
    "#     xml_path: PathOrFileType,\n",
    "#     query: str,\n",
    "#     schema_type: str = \"annotation\",\n",
    "#     validation: str = \"skip\",\n",
    "# ) -> list[dict[str, Any]]:\n",
    "#     schema = cached_sentinel1_schemas(schema_type)\n",
    "#     xml_tree = ElementTree.parse(xml_path)\n",
    "#     tag: Any = schema.decode(xml_tree, query, validation=validation)\n",
    "#     if tag is None:\n",
    "#         tag = []\n",
    "#     elif isinstance(tag, dict):\n",
    "#         tag = [tag]\n",
    "#     tag_list: list[dict[str, Any]] = tag\n",
    "#     assert isinstance(tag_list, list), f\"{type(tag_list)} is not list\"\n",
    "#     return tag_list\n",
    "\n",
    "\n",
    "# def open_coordinate_conversion_dataset(\n",
    "#     annotation_path, attrs: dict[str, Any] = {}\n",
    "# ) -> xr.Dataset:\n",
    "#     coordinate_conversion = parse_tag_as_list(\n",
    "#         annotation_path, \".//coordinateConversionList/coordinateConversion\"\n",
    "#     )\n",
    "#     if len(coordinate_conversion) == 0:\n",
    "#         raise TypeError(\"coordinateConversion tag not present in annotations\")\n",
    "\n",
    "#     gr0 = []\n",
    "#     sr0 = []\n",
    "#     azimuth_time = []\n",
    "#     slant_range_time = []\n",
    "#     srgrCoefficients: list[list[float]] = []\n",
    "#     grsrCoefficients: list[list[float]] = []\n",
    "#     for values in coordinate_conversion:\n",
    "#         sr0.append(values[\"sr0\"])\n",
    "#         gr0.append(values[\"gr0\"])\n",
    "#         azimuth_time.append(values[\"azimuthTime\"])\n",
    "#         slant_range_time.append(values[\"slantRangeTime\"])\n",
    "#         srgrCoefficients.append(\n",
    "#             [float(v) for v in values[\"srgrCoefficients\"][\"$\"].split()]\n",
    "#         )\n",
    "#         grsrCoefficients.append(\n",
    "#             [float(v) for v in values[\"grsrCoefficients\"][\"$\"].split()]\n",
    "#         )\n",
    "\n",
    "#     coords: dict[str, Any] = {}\n",
    "#     data_vars: dict[str, Any] = {}\n",
    "#     coords[\"azimuth_time\"] = [np.datetime64(dt, \"ns\") for dt in azimuth_time]\n",
    "#     coords[\"degree\"] = list(range(len(srgrCoefficients[0])))\n",
    "\n",
    "#     data_vars[\"gr0\"] = (\"azimuth_time\", gr0)\n",
    "#     data_vars[\"sr0\"] = (\"azimuth_time\", sr0)\n",
    "#     data_vars[\"slant_range_time\"] = (\"azimuth_time\", slant_range_time)\n",
    "#     data_vars[\"srgrCoefficients\"] = ((\"azimuth_time\", \"degree\"), srgrCoefficients)\n",
    "#     data_vars[\"grsrCoefficients\"] = ((\"azimuth_time\", \"degree\"), grsrCoefficients)\n",
    "\n",
    "#     return xr.Dataset(data_vars=data_vars, coords=coords, attrs=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913fddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5kB\n",
      "Dimensions:           (azimuth_time: 28, degree: 9)\n",
      "Coordinates:\n",
      "  * azimuth_time      (azimuth_time) datetime64[ns] 224B 2024-12-09T01:58:51....\n",
      "  * degree            (degree) int64 72B 0 1 2 3 4 5 6 7 8\n",
      "Data variables:\n",
      "    sr0               (azimuth_time) float64 224B 8.001e+05 ... 8.001e+05\n",
      "    gr0               (azimuth_time) float64 224B 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    slant_range_time  (azimuth_time) float64 224B 0.005338 0.005338 ... 0.005338\n",
      "    srgrCoefficients  (azimuth_time, degree) float64 2kB 0.03615 ... -7.62e-39\n",
      "    grsrCoefficients  (azimuth_time, degree) float64 2kB 8.001e+05 ... -6.03e-45\n"
     ]
    }
   ],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "# import glob\n",
    "# import numpy as np\n",
    "# import xarray as xr\n",
    "# import pandas as pd\n",
    "\n",
    "# def extract_geolocation_grid(annotation_xml):\n",
    "#     tree = ET.parse(annotation_xml)\n",
    "#     root = tree.getroot()\n",
    "#     geo_points = root.findall(\".//geolocationGridPoint\")\n",
    "\n",
    "#     pixel, line = [], []\n",
    "#     lat, lon = [], []\n",
    "#     az_time, height = [], []\n",
    "\n",
    "#     for point in geo_points:\n",
    "#         pixel.append(float(point.find(\"pixel\").text))\n",
    "#         line.append(float(point.find(\"line\").text))\n",
    "#         lat.append(float(point.find(\"latitude\").text))\n",
    "#         lon.append(float(point.find(\"longitude\").text))\n",
    "#         az_time.append(point.find(\"azimuthTime\").text)\n",
    "#         height.append(float(point.find(\"height\").text))\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         \"pixel\": pixel,\n",
    "#         \"line\": line,\n",
    "#         \"lat\": lat,\n",
    "#         \"lon\": lon,\n",
    "#         \"azimuth_time\": pd.to_datetime(az_time),\n",
    "#         \"height\": height,\n",
    "#     })\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "# def create_coordinate_conversion_from_geogrid(df, poly_degree=1):\n",
    "#     times = sorted(df['azimuth_time'].unique())\n",
    "#     srgrCoeffs, grsrCoeffs, gr0s, sr0s, slant_range_times = [], [], [], [], []\n",
    "#     # print(times)\n",
    "\n",
    "#     for t in times:\n",
    "#         sub = df[df['azimuth_time'] == t]\n",
    "#         # print(len(sub))\n",
    "#         # if len(sub) < poly_degree + 1:\n",
    "#         #     continue  # not enough points to fit\n",
    "#         print(\"123\")\n",
    "#         # Simulate slant-range and ground-range (e.g., using pixel and line)\n",
    "#         sr = np.array(sub['pixel'])  # pixel as proxy for slant-range\n",
    "#         gr = np.array(sub['lon'])    # longitude as proxy for ground-range\n",
    "#         az = np.array(sub['lat'])    # latitude as proxy for azimuth\n",
    "\n",
    "#         # Fit polynomials\n",
    "#         srgr = np.polyfit(sr, gr, deg=poly_degree).tolist()\n",
    "#         grsr = np.polyfit(gr, sr, deg=poly_degree).tolist()\n",
    "\n",
    "#         srgrCoeffs.append(srgr)\n",
    "#         grsrCoeffs.append(grsr)\n",
    "#         sr0s.append(sr[0])\n",
    "#         gr0s.append(gr[0])\n",
    "#         slant_range_times.append(0.0)  # dummy value\n",
    "\n",
    "#     return xr.Dataset(\n",
    "#         {\n",
    "#             \"gr0\": (\"azimuth_time\", gr0s),\n",
    "#             \"sr0\": (\"azimuth_time\", sr0s),\n",
    "#             \"slant_range_time\": (\"azimuth_time\", slant_range_times),\n",
    "#             \"srgrCoefficients\": ((\"azimuth_time\", \"degree\"), srgrCoeffs),\n",
    "#             \"grsrCoefficients\": ((\"azimuth_time\", \"degree\"), grsrCoeffs),\n",
    "#         },\n",
    "#         coords={\n",
    "#             \"azimuth_time\": np.array(times[:len(srgrCoeffs)], dtype=\"datetime64[ns]\"),\n",
    "#             \"degree\": list(range(poly_degree + 1)),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "xml_path = \"docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE/annotation/s1a-iw-grd-vh-20241209t015852-20241209t015917-056909-06fd49-002_updated.xml\"\n",
    "\n",
    "# Replace with the actual annotation file path\n",
    "# xml_path = \"path/to/annotation.xml\"\n",
    "\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "ns = {\"s1\": \"http://www.esa.int/safe/sentinel-1.0\"}  # adjust if needed\n",
    "\n",
    "coordinate_nodes = root.findall(\".//coordinateConversionList/coordinateConversion\")\n",
    "\n",
    "azimuth_time = []\n",
    "sr0 = []\n",
    "gr0 = []\n",
    "slant_range_time = []\n",
    "srgr_coeffs = []\n",
    "grsr_coeffs = []\n",
    "\n",
    "for node in coordinate_nodes:\n",
    "    azimuth_time.append(np.datetime64(node.findtext(\"azimuthTime\"), \"ns\"))\n",
    "    sr0.append(float(node.findtext(\"sr0\")))\n",
    "    gr0.append(float(node.findtext(\"gr0\")))\n",
    "    slant_range_time.append(float(node.findtext(\"slantRangeTime\")))\n",
    "\n",
    "    srgr = [float(x) for x in node.findtext(\"srgrCoefficients\").split()]\n",
    "    grsr = [float(x) for x in node.findtext(\"grsrCoefficients\").split()]\n",
    "    srgr_coeffs.append(srgr)\n",
    "    grsr_coeffs.append(grsr)\n",
    "\n",
    "degree = list(range(len(srgr_coeffs[0])))\n",
    "\n",
    "coordinate_conversion = xr.Dataset(\n",
    "    coords={\n",
    "        \"azimuth_time\": (\"azimuth_time\", azimuth_time),\n",
    "        \"degree\": (\"degree\", degree),\n",
    "    },\n",
    "    data_vars={\n",
    "        \"sr0\": (\"azimuth_time\", sr0),\n",
    "        \"gr0\": (\"azimuth_time\", gr0),\n",
    "        \"slant_range_time\": (\"azimuth_time\", slant_range_time),\n",
    "        \"srgrCoefficients\": ((\"azimuth_time\", \"degree\"), srgr_coeffs),\n",
    "        \"grsrCoefficients\": ((\"azimuth_time\", \"degree\"), grsr_coeffs),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(coordinate_conversion)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Locate annotation XML\n",
    "\n",
    "# 2. Extract grid\n",
    "# geo_df = extract_geolocation_grid(annotation_xml)\n",
    "# print(geo_df)\n",
    "\n",
    "# 3. Create coordinate_conversion\n",
    "# coordinate_conversion = create_coordinate_conversion_from_geogrid(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59769cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_radiometric_calibration_lut(safe_folder_path, representation_type=\"sigmaNought\"):\n",
    "    \"\"\"\n",
    "    Parsing LUT for radiometric calibration bt reading the calibration xml files.\n",
    "\n",
    "    This function reads calibration related XML files within the 'annotation/calibration' folder in the\n",
    "    provided SAFE directory path,\n",
    "    and returns an xarray.Dataset with LUT for available polarizations based on the representation type as required.\n",
    "\n",
    "    Arguments:\n",
    "        safe_folder_path (str): Path to the root directory of the Sentinel-1 SAFE format product.\n",
    "        representation_type (str, optional): Type of backscatter representation to be used. \n",
    "        Options are:\n",
    "            - 'sigmaNought' (default)\n",
    "            - 'betaNought'\n",
    "            - 'gamma'\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset: A dataset containing the LUT for radiometric calibration for available polarizations\n",
    "        (e.g., 'VV', 'VH')\n",
    "\n",
    "    Raises Exception:\n",
    "        Exception: representation_type is not valid\n",
    "        FileNotFoundError: If the 'calibration' folder or required XML files are missing,\n",
    "    \"\"\"\n",
    "\n",
    "    supporting_representation_types=[\"sigmaNought\",\"betaNought\",\"gamma\"]\n",
    "    if representation_type not in supporting_representation_types:\n",
    "        raise Exception(f\"representation_type {representation_type} is not supported. Supporting types are {supporting_representation_types}\")\n",
    "\n",
    "    calibration_path = os.path.join(safe_folder_path, \"annotation/calibration/\")\n",
    "    if not os.path.exists(calibration_path):\n",
    "        raise FileNotFoundError(f\"'calibration' folder not found inside {safe_folder_path}\")\n",
    "\n",
    "    # Find XML files starting with 's1a-iw-grd' (case insensitive)\n",
    "    xml_files = [f for f in os.listdir(calibration_path) if f.lower().startswith('calibration') and f.lower().endswith('.xml')]\n",
    "    if not xml_files:\n",
    "        raise FileNotFoundError(\"No suitable calibration XML files found in 'calibration' folder\")\n",
    "    lut_dict={}\n",
    "    for xml_file in xml_files:\n",
    "\n",
    "        polarizations = [\"vv\", \"vh\", \"hh\", \"hv\"]\n",
    "        band_name = None\n",
    "        for pol in polarizations:\n",
    "            if pol in xml_file.lower():\n",
    "                band_name = pol.upper()\n",
    "                break\n",
    "\n",
    "        if not band_name:\n",
    "            raise FileNotFoundError(f\"Polarization type not found in file name: {xml_file}\")\n",
    "\n",
    "        print(f\"Reading calibration for {band_name} band\")\n",
    "\n",
    "        xml_path = os.path.join(calibration_path, xml_file)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        lines = []\n",
    "        pixels = None\n",
    "        correction_values = []\n",
    "\n",
    "        for calib_vec in root.findall('.//calibrationVector'):\n",
    "            line = int(calib_vec.find('line').text)\n",
    "            pixel_str = calib_vec.find('pixel').text.strip()\n",
    "            value_str = calib_vec.find(representation_type).text.strip()\n",
    "\n",
    "            pixels = [int(x) for x in pixel_str.split()]\n",
    "            values = [float(x) for x in value_str.split()]\n",
    "\n",
    "            lines.append(line)\n",
    "            correction_values.append(values)\n",
    "\n",
    "        beta_array = np.array(correction_values)\n",
    "        lut = xr.DataArray(beta_array, coords={\"line\": lines, \"pixel\": pixels}, dims=[\"line\", \"pixel\"])\n",
    "        lut_dict[band_name]= lut    \n",
    "    lut_ds = xr.Dataset(lut_dict)\n",
    "    print(\"Radiometric calibration LUT created successfully\")\n",
    "    return lut_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd1e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# # from pysarflow import parse_radiometric_calibration_lut\n",
    "\n",
    "# def lut_pixel_line_to_time(lut_ds, acquisition):\n",
    "#     # Convert 'line' index to azimuth_time\n",
    "#     # Assumptions:\n",
    "#     # - acquisition.attrs['startTime'] is a pd.Timestamp\n",
    "#     # - acquisition.attrs['prf'] is Pulse Repetition Frequency (Hz)\n",
    "#     # - acquisition has 'slant_range_time' or 'ground_range' coords\n",
    "\n",
    "#     start_time = pd.to_datetime(acquisition.attrs['startTime'])\n",
    "#     prf = acquisition.attrs.get('prf', 1680)  # default PRF example\n",
    "\n",
    "#     # Calculate azimuth time for each line in LUT\n",
    "#     lut_azimuth_time = start_time + pd.to_timedelta(lut_ds.line.values / prf, unit='s')\n",
    "\n",
    "#     # For slant_range_time: Map pixel index to slant range time\n",
    "#     # Assuming acquisition.slant_range_time exists and is evenly spaced\n",
    "#     # Map pixel index to slant_range_time by interpolation or indexing\n",
    "\n",
    "#     slant_range_time_arr = acquisition.slant_range_time.values\n",
    "#     pixel_indices = lut_ds.pixel.values\n",
    "\n",
    "#     # Linear interpolation of pixel index to slant_range_time values\n",
    "#     from numpy import interp\n",
    "#     lut_slant_range_time = interp(pixel_indices, range(len(slant_range_time_arr)), slant_range_time_arr)\n",
    "\n",
    "#     # Assign new coords to each DataArray in lut_ds\n",
    "#     lut_ds_new = lut_ds.copy()\n",
    "#     for pol in lut_ds_new.data_vars:\n",
    "#         lut_ds_new[pol] = lut_ds_new[pol].assign_coords(\n",
    "#             azimuth_time=(\"line\", lut_azimuth_time),\n",
    "#             slant_range_time=(\"pixel\", lut_slant_range_time)\n",
    "#         ).rename({\"line\": \"azimuth_time\", \"pixel\": \"slant_range_time\"})\n",
    "\n",
    "#     return lut_ds_new\n",
    "\n",
    "# lut_ds_new = parse_radiometric_calibration_lut(zip_safe_path, representation_type=\"sigmaNought\")\n",
    "\n",
    "# # ls_ds_new = lut_pixel_line_to_time(lut_ds, acquisition):\n",
    "\n",
    "# lut_interp = lut_ds_new.interp(\n",
    "#     azimuth_time=acquisition.azimuth_time,\n",
    "#     slant_range_time=acquisition.slant_range_time\n",
    "# )\n",
    "# beta_nought = ds / (lut_interp ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab16e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def slant_range_time_to_ground_range(\n",
    "    azimuth_time: xr.DataArray,\n",
    "    slant_range_time: xr.DataArray,\n",
    "    coordinate_conversion: xr.Dataset,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"Convert slant range time to ground range using the coordinate conversion metadata.\n",
    "\n",
    "    :param azimuth_time: azimuth time coordinates\n",
    "    :param slant_range_time: slant range time\n",
    "    :param coordinate_conversion: coordinate conversion dataset.\n",
    "    The coordinate conversion dataset can be opened using the measurement sub-groub `coordinate_conversion`\n",
    "    \"\"\"\n",
    "    slant_range = SPEED_OF_LIGHT / 2.0 * slant_range_time\n",
    "    sr0 = coordinate_conversion.sr0.interp(azimuth_time=azimuth_time)\n",
    "    srgrCoefficients = coordinate_conversion.srgrCoefficients.interp(\n",
    "        azimuth_time=azimuth_time,\n",
    "    )\n",
    "    x = slant_range - sr0\n",
    "    ground_range = (srgrCoefficients * x**srgrCoefficients.degree).sum(\"degree\")\n",
    "    return ground_range  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "def interp_sar(\n",
    "    data: xr.DataArray,\n",
    "    azimuth_time: xr.DataArray,\n",
    "    slant_range_time: xr.DataArray | None = None,\n",
    "\n",
    "    method: xr.core.types.InterpOptions = \"nearest\",\n",
    "    ground_range: xr.DataArray | None = None,\n",
    "    coordinate_conversion:xr.DataArray | None = None\n",
    ") -> xr.DataArray:\n",
    "    if ground_range is None:\n",
    "        assert slant_range_time is not None\n",
    "        ground_range = slant_range_time_to_ground_range(\n",
    "            azimuth_time, slant_range_time, coordinate_conversion\n",
    "        )\n",
    " \n",
    "\n",
    "    interpolated = data.interp(\n",
    "        azimuth_time=azimuth_time, ground_range=ground_range, method=method\n",
    "    )\n",
    "    \n",
    "    return interpolated.assign_attrs(data.attrs)\n",
    "\n",
    "# def interp_sar(data, azimuth_time, slant_range_time, coordinate_conversion, method='linear'):\n",
    "#     # Convert target times to line/pixel\n",
    "#     # target_line, target_pixel = coordinate_conversion(azimuth_time, slant_range_time)\n",
    "#     # Example: Suppose coordinate_conversion is a Dataset with variables 'line' and 'pixel'\n",
    "#     target_line = coordinate_conversion['line'].interp(\n",
    "#         azimuth_time=azimuth_time, slant_range_time=slant_range_time\n",
    "#     )\n",
    "#     target_pixel = coordinate_conversion['pixel'].interp(\n",
    "#         azimuth_time=azimuth_time, slant_range_time=slant_range_time\n",
    "#     )\n",
    "\n",
    "#     # Interpolate using the correct dimensions\n",
    "#     interpolated = data.interp(\n",
    "#         line=target_line,\n",
    "#         pixel=target_pixel,\n",
    "#         method=method\n",
    "#     )\n",
    "#     return interpolated.assign_attrs(data.attrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d92fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisition.azimuth_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "283b2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((acquisition.azimuth_time),(acquisition.slant_range_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cd209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading calibration for VV band\n",
      "2024-12-09T01:58:52.968127 khjkhjk\n",
      "2024-12-09T01:58:53.968127 khjkhjk\n",
      "2024-12-09T01:58:54.968127 khjkhjk\n",
      "2024-12-09T01:58:55.968127 khjkhjk\n",
      "2024-12-09T01:58:56.968127 khjkhjk\n",
      "2024-12-09T01:58:57.968127 khjkhjk\n",
      "2024-12-09T01:58:58.968127 khjkhjk\n",
      "2024-12-09T01:58:59.968127 khjkhjk\n",
      "2024-12-09T01:59:00.968127 khjkhjk\n",
      "2024-12-09T01:59:01.968127 khjkhjk\n",
      "2024-12-09T01:59:02.968127 khjkhjk\n",
      "2024-12-09T01:59:03.968127 khjkhjk\n",
      "2024-12-09T01:59:04.968127 khjkhjk\n",
      "2024-12-09T01:59:05.968127 khjkhjk\n",
      "2024-12-09T01:59:06.968127 khjkhjk\n",
      "2024-12-09T01:59:07.968127 khjkhjk\n",
      "2024-12-09T01:59:08.968127 khjkhjk\n",
      "2024-12-09T01:59:09.968127 khjkhjk\n",
      "2024-12-09T01:59:10.968127 khjkhjk\n",
      "2024-12-09T01:59:11.968127 khjkhjk\n",
      "2024-12-09T01:59:12.968127 khjkhjk\n",
      "2024-12-09T01:59:13.968127 khjkhjk\n",
      "2024-12-09T01:59:14.968127 khjkhjk\n",
      "2024-12-09T01:59:15.968127 khjkhjk\n",
      "2024-12-09T01:59:16.968127 khjkhjk\n",
      "2024-12-09T01:59:17.968127 khjkhjk\n",
      "2024-12-09T01:59:18.968127 khjkhjk\n",
      "Reading calibration for VH band\n",
      "2024-12-09T01:58:52.968127 khjkhjk\n",
      "2024-12-09T01:58:53.968127 khjkhjk\n",
      "2024-12-09T01:58:54.968127 khjkhjk\n",
      "2024-12-09T01:58:55.968127 khjkhjk\n",
      "2024-12-09T01:58:56.968127 khjkhjk\n",
      "2024-12-09T01:58:57.968127 khjkhjk\n",
      "2024-12-09T01:58:58.968127 khjkhjk\n",
      "2024-12-09T01:58:59.968127 khjkhjk\n",
      "2024-12-09T01:59:00.968127 khjkhjk\n",
      "2024-12-09T01:59:01.968127 khjkhjk\n",
      "2024-12-09T01:59:02.968127 khjkhjk\n",
      "2024-12-09T01:59:03.968127 khjkhjk\n",
      "2024-12-09T01:59:04.968127 khjkhjk\n",
      "2024-12-09T01:59:05.968127 khjkhjk\n",
      "2024-12-09T01:59:06.968127 khjkhjk\n",
      "2024-12-09T01:59:07.968127 khjkhjk\n",
      "2024-12-09T01:59:08.968127 khjkhjk\n",
      "2024-12-09T01:59:09.968127 khjkhjk\n",
      "2024-12-09T01:59:10.968127 khjkhjk\n",
      "2024-12-09T01:59:11.968127 khjkhjk\n",
      "2024-12-09T01:59:12.968127 khjkhjk\n",
      "2024-12-09T01:59:13.968127 khjkhjk\n",
      "2024-12-09T01:59:14.968127 khjkhjk\n",
      "2024-12-09T01:59:15.968127 khjkhjk\n",
      "2024-12-09T01:59:16.968127 khjkhjk\n",
      "2024-12-09T01:59:17.968127 khjkhjk\n",
      "2024-12-09T01:59:18.968127 khjkhjk\n",
      "Radiometric calibration LUT created successfully\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input DataArray is not 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/z7/dwc0g9dx10n413p0gzrtz1lh0000gn/T/ipykernel_70777/3356918560.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m     azimuth_time=acquisition.azimuth_time,\n\u001b[32m      9\u001b[39m     ground_range=acquisition.slant_range_time\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m geocoded = interp_sar(\n\u001b[32m     13\u001b[39m             data=beta_nought,\n\u001b[32m     14\u001b[39m             azimuth_time=acquisition.azimuth_time,\n\u001b[32m     15\u001b[39m             slant_range_time=acquisition.slant_range_time,\n",
      "\u001b[32m/var/folders/z7/dwc0g9dx10n413p0gzrtz1lh0000gn/T/ipykernel_70777/2852510672.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data, azimuth_time, slant_range_time, method, ground_range, coordinate_conversion)\u001b[39m\n\u001b[32m     36\u001b[39m             azimuth_time, slant_range_time, coordinate_conversion\n\u001b[32m     37\u001b[39m         )\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     interpolated = data.interp(\n\u001b[32m     41\u001b[39m         azimuth_time=azimuth_time, ground_range=ground_range, method=method\n\u001b[32m     42\u001b[39m     )\n\u001b[32m     43\u001b[39m \n",
      "\u001b[32m~/Rabina/CDE II/software_development/py_sar_flow/.venv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, coords, method, assume_sorted, kwargs, method_non_numeric, **coords_kwargs)\u001b[39m\n\u001b[32m   3766\u001b[39m             kwargs = {}\n\u001b[32m   3767\u001b[39m \n\u001b[32m   3768\u001b[39m         coords = either_dict_or_kwargs(coords, coords_kwargs, \u001b[33m\"interp\"\u001b[39m)\n\u001b[32m   3769\u001b[39m         indexers = dict(self._validate_interp_indexers(coords))\n\u001b[32m-> \u001b[39m\u001b[32m3770\u001b[39m         obj = self \u001b[38;5;28;01mif\u001b[39;00m assume_sorted \u001b[38;5;28;01melse\u001b[39;00m self.sortby(list(coords))\n\u001b[32m   3771\u001b[39m \n\u001b[32m   3772\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m maybe_variable(obj, k):\n\u001b[32m   3773\u001b[39m             \u001b[38;5;66;03m# workaround to get variable for dimension without coordinate.\u001b[39;00m\n",
      "\u001b[32m~/Rabina/CDE II/software_development/py_sar_flow/.venv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, variables, ascending)\u001b[39m\n\u001b[32m   7970\u001b[39m         aligned_other_vars = cast(tuple[DataArray, ...], aligned_vars[\u001b[32m1\u001b[39m:])\n\u001b[32m   7971\u001b[39m         vars_by_dim = defaultdict(list)\n\u001b[32m   7972\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m data_array \u001b[38;5;28;01min\u001b[39;00m aligned_other_vars:\n\u001b[32m   7973\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m data_array.ndim != \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7974\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Input DataArray is not 1-D.\"\u001b[39m)\n\u001b[32m   7975\u001b[39m             (key,) = data_array.dims\n\u001b[32m   7976\u001b[39m             vars_by_dim[key].append(data_array)\n\u001b[32m   7977\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: Input DataArray is not 1-D."
     ]
    }
   ],
   "source": [
    "# beta_nought=radiometric_calibrated_ds\n",
    "# beta_nought=radiometric_calibrated_ds\n",
    "safe_folder = \"docs/data/S1A_IW_GRDH_1SDV_20241209T015852_20241209T015917_056909_06FD49_AE78.SAFE\"\n",
    "beta_nought=parse_beta_lut(safe_folder, representation_type=\"betaNought\")\n",
    "\n",
    "beta_nought = beta_nought.rename({'line': 'azimuth_time', 'pixel': 'ground_range'})\n",
    "beta_nought = beta_nought.assign_coords(\n",
    "    azimuth_time=acquisition.azimuth_time,\n",
    "    ground_range=acquisition.slant_range_time\n",
    ")\n",
    "\n",
    "geocoded = interp_sar(\n",
    "            data=beta_nought,\n",
    "            azimuth_time=acquisition.azimuth_time,\n",
    "            slant_range_time=acquisition.slant_range_time,\n",
    "            coordinate_conversion=coordinate_conversion\n",
    "            # method=interp_method,\n",
    "        )\n",
    "\n",
    "# geocoded = beta_nought.interp(\n",
    "#     x=beta_nought['x'],  # you need to define these\n",
    "#     y=beta_nought['y'],\n",
    "#     method='linear'\n",
    "# )\n",
    "\n",
    "\n",
    "# geocoded, simulated_beta_nought = do_terrain_correction(\n",
    "    #     product=product,\n",
    "    #     dem_raster=dem_raster,\n",
    "    #     correct_radiometry=correct_radiometry,\n",
    "    #     interp_method=interp_method,\n",
    "    #     grouping_area_factor=grouping_area_factor,\n",
    "    #     radiometry_chunks=radiometry_chunks,\n",
    "    #     radiometry_bound=radiometry_bound,\n",
    "    #     seed_step=seed_step,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60054f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aaa69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_nought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21834006",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lat_min, lon_max, lat_max = 13.45, 42.40, 13.55, 42.50\n",
    "output_dem_path=\"dem2.tif\"\n",
    "download_dem(lon_min, lat_min, lon_max, lat_max,output_dem_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysarflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
